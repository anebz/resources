# 12. Game Theory 2: Nonzero-sum and cooperative games

## 12.1. The Nash equilibrium

The prisoner's dilemma is an example of a nonzero-sum game, because the loss or gain of one player isn't the opposite of that made my the other player. If we sum up the utilities in each box they don't always equal zero.

| | C1: confess  | C2: don't |
| - | - | - |
| R1: confess | -10, -10 | -1, -20 |
| R2: don't | -20, -1 | -2, -2 |

(R1, C1) is in equilibrium because if row knew that Col was going to confess, C1, then he wouldn't be better off by switching to another strategy, and if Col knew that Row was going to confess, R1, then he would also be best off by not switching his strategy.

Nash's idea: rational players will do whatever they can to insure that they don't feel unnecessarily unhappy about their decision. If a rational player is about to play a strategy and knows that he could do something better, given that his assumption about the opponent are held fixed, then the player won't choose the nonoptimal strategy. Only strategies that fulfill this 'not better to switch' test will be chosen. And this holds true for every player, so rational players will always play strategies that constitute *Nash equilibriums*.

Nash defines equilibrium in his PhD in 1950 as follows: 

> an equilibrium point is a set of strategies such that each player's strategy maximizes his pay-off if the strategies of the others are held fixed. Thus each player's strategy is optimal against those of the others

Most nonzero-sum games have multiple Nash equilibriums, so it can't be properly solved, or can't figure out exactly what rational players would do, by just applying Nash's equilibrium concept. Example, stag hunt

| | C1: hunt stag  | C2: don't |
| - | - | - |
| R1: hunt stag | 25, 25 | 0, 5 |
| R2: don't | 5, 0 | 5, 5 |

In this game there are two pure Nash equilibria, (R1, C1) and (R2, C2). There are also two mixed Nash equilibria, (R1 1/5, C1 1/5). If Col plays C1 with probability 1/5, then it would be optimal for Row to play R1 with probability 1/5.

If your subjective probability is higher than 1/5 that Col will hunt for stag given that you do so, then you should also hunt for stag. And Col should reason the exact same way because the game is symmetric. So we get two clear and unambiguous recommendations.

Nash's equilibrium concept played no role whatsoever in the alternative analysis, the strategy to be chosen by the other player was treated as a state of the world, to which we assigned a subjective probability. So what's the point of identifying Nash's equilibria, why not treat nooncooperative nonzero-sum games as individual decisions under risk?

We have assumed that everyone wants to maximize expected utility, but that doesn't have to be the case. What's best for each (risk-averse) individual may not be the best for a group as a whole. In order to reach the outcome that's best for a group playing stag hunt, we have to insure that the players are prepared to take at least moderate risks.

'Pareto efficient': a state is Pareto efficient iff no one's utility level can be increased unless the utility level for someone else is decreased. (R2, C2) isn't a Pareto efficient state but (R1, C1) is. Many economists think that Pareto efficiency is a plausible minimal normative condition. The idea is that all states that aren't Pareto efficient should be avoided. Individual rationality doesn't by any means guarantee that society will reach a Pareto efficient state. If you believe to a sufficiently strong degree that your opponent will hunt for hare, then it's rational for you to hunt for hare too, even though the outcome won't be Pareto efficient.

## 12.2. The battle of the sexes and chicken

Unlike the stag hunt, this game can't be dealt with by 'merely' establishing a certain trust among the players.

A married couple wants to spend time together, Row would prefer to go the opera, Col to the football game.

| | C1: opera | C2: football |
| - | - | - |
| R1: opera | 2,1 | 0,0 |
| R2: football | 0,0 | 1,2 |

The battle of the sexes is a nooncooperative game, even if the players communicate and make agreements, there's no way in which players can form binding agreements. There are two pure equilibria, (R1,C1) and (R2,C2), and also a mixed equilibrium, (R1 2/3 C1 1/3).

Both players will reason the same way if they're rational, so Row will pick R1, Col C2, and both will get 0. And if Row were for any reason to choose R2, then Col would reason the same way, and both would end up with 0 again.

If Nash is right, rational players would never choose (R2,C1) or (R1,C2), but we have shown that those could be chosen. So what has gone wrong? There's currently no agreement on this in the literature.

The battle of the sexes can also be viewed as an individual decision under risk or uncertainty. Each player's choice esentially depends on what she thinks the other player will do, they can assign probabilities to what the other player will do, and then calculate their own strategy. But we can easily imagine situations where the player isn't prepared to assign any probability to what the opponent is likely to do. So what should the players do? There's no agreement in the literature.

## 12.3. The bargaining problem

Up until now games have been nooncooperative, meaning that the players are unable to form binding agreements on how to coordinate their actions. In this section we discuss a famous cooperative game:

> There are $100 on the table, and two players. Each must write down a demand of how much she would like to get from the money. If the sum of both exceeds $100, both get nothing. Otherwise they get what they asked for. The players can communicate and form whatever binding agreement they wish.

| | C1: $80 | C2: $20 |
| - | - | - |
| R1: $80 | 0,0 | $80,$20 |
| R2: $20 | $20,$80 | 0,0 |

In a simpler form, rules state that one must take $80 and the other $20. There are 2 pure Nash equilibria, (R1, C2) and (R2, C1), and given that each player's utility of money is linear, the mixed solution is ([R1 8/10, R2 2/10], [C1 8/10, C2 2/10]). So this looks like the battle of the sexes.

In the general case, each x belonging to [0,100] is a Nash equilibrium, so how do we solve the plethora of equilibria? Nash hypothesized that rational players facing the bargaining problem would agree on 4 axioms, and these axioms stipulate some conditions for hat would be required of a rational solution of the problem. Nash said there's just one way of dividing the money tht fulfills all four axioms. There's a unique best way to divide the money, and if the players are sufficiently rational, they will find this solution.

Nash: if Row gets u(x) utility and Col gets v(100-x) utility, then rational players will always agree to divide the money such that u(x) * v(100-x) is maximized. So there's only one Nash solution to this problem, despite there being infinitely many Nash equilibria. The axioms:

1. Nash equilibrium: whatever rational bargainers agree on, the chosen strategies will be a Nash equilibrium, and a Pareto optimum
2. Irrelevance of utility representation: the chosen strategies should be invariant to the choice of vNM utility function to represent a player's preferences
3. Independnce of irrelevant alternatives: the solution doesn't depend on whether irrelevant strategies (those not preferred by any player) are added or removed from the set of alternative strategies.
4. Symmetry: the players' strategies will be identical iff their utility functions are identical

## 12.4. Iterated games

Game theorists have discovered that the equilibrium strategies will sometimes be different in iterated games, which can be finite or infinitely iterated.

A finitely iterated game is a game that's iterated a finite number of times, and the players are aware of when the last round takes place. In the infinitely iterated case, it doesn't matter if the game is played infinite times, but the players don't know when the last round is. The strategies can vary greatly in that last round.

## 12.5. Game theory and evolution

In evolutionary game theory, 'players' are usually different subgroups of species, which differ with respect to some biological characteristics. Players don't necessarily need to be aware that they're playing a game, or aware that they're choosing from a set of alternative strategies.

It can be shown that every *evolutionary stable strategy* (ESS) is part of a Nash equilibrium, but not every Nash equilibrium has only evolutionary stable strategies.

Rats in NY can hawk (fight with other rats) with probability p, or dove (play nice) with probability 1-p. Now a group of rats arrive to NY from New Jersey, with a probability to hawk of q, and a probability to dove of 1-q. The mixed strategy played by the NY rats is in an *evolutionary stable equilibrium* iff it has a higher expected utility than that played by the New Jersey rats.

If the mixed strategy of NY rats is in equilibrium, then it won't change with the arrival of New Jersey rats, actually New Jersey rats will learn to adopt the strategy of NY rats.

Formally, a strategy *x* is evolutionary stable iff the following conditions hold. EU(x,y) is the expected utility of playing strategy *x* against someone playing strategy *y*.

> EU(x,x) >= EU(x,y) for all y

And

> EU(x,x) >= EU(y,x) or EU(x,y) > EU(y,y) for all y

## 12.6. Game theory and ethics

Nash's results are a counterexample to the widely accepted Hume's law, which holds that no moral statement can be derived from a set of purely nonmoral statements. Nash's axioms are statements about rational behavior, not statements about what it would be morally right to do.

About the prisoner's dilemma, Gaunthier argues that it's rational to cooperate in the finitely iterated prisoner's dilemma if one thinks one is playing against a cooperatively minded opponent, otherwise it's rational to play nooncooperative strategies.