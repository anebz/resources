# 10. Risk aversion

Is it always rational to be risk averse? Some risk aversion meanings are compatible with the principle of maximizing expected utility, others aren't. We discuss three of the most influential notions of risk aversion discussed in the literature:

1. Aversion agains actuarial risks
2. Aversion against utility risks
3. Aversion against epistemic risks

## 10.1. Actuarial risk aversion

According to the Economics Nobel Prize winner Kenneth Arrow, A risk averter is defined as one who, starting from a position of certainty, is unwilling to take a bet which is actuarially fair.

For example, after winning a tournament, taking the sure $1M rather than $2M or $0 depending on the toss of a coin.

The actuarial notion of risk aversion is fully compatible with the principle of maximizing expected utility. Arrow's main point is tht intuitions about risk aversion can be accounted for *without* modifying the expected utility principle. The key insight is that if the dm's utility function is concave, then the expected utility of getting the double prize for sure will always exceed the expected utility of a fifty-fifty chance of getting either 2X of nothing.

A dm whose utility function is concave will always prefer getting a smaller prize for sure to an actuarially fair lottery over some larger and smaller prices.

An objection to this theory is that no matter what its normative implications might me, it fails to distinguish between our attitude to risk and our attitude to certain outcomes. The identification of risk aversion with properties of the dm's utility function overlooks a fundamental distinction between utility and risk. We can't know if one decision is based on someone's utility function (greed for money or lack thereof), or their own risk aversion.

## 10.2. Aversion against utility risks

Decision theorists unhappy with Arrow's account of risk aversion might think that a risk-averse dm ought to replace the expected utility principle with some other decision rule.

A more promising proposal is to replace the principle of maximizing expected utility with what Lara Buchak calls the principle of maximizing risk-weighted expected utility. According to her principle, the possibility of a potential utility gain over the minimum improves the gamble above its minimum utility value by the size of the gain multiplied by a *function of* the probability of realizing that gain.

Two gambles:

| | 1-p | p | 
| - | - | - |
| Gamble 1 | $0 | $100 |
| Gamble 2 | $40 | $40 |

Example: we win x with prob 1-p, or win y with prob p. x >= y. The expected utility of the first gamble is (1-p) * u(0) + p * u($100) == u(0) + p(u(100) - u(0)). Buchak's proposal is that the possibility of gaining $100 with prob p should be weighted with the agent's 'risk function' r, which assigns a value between 0 and 1 to every probability p of realizing a gain over the minimum utility value. The risk-weighted expected utility of the first gamble:

> u(0) + r(p) * (u(100) - u(0))

If r(p) is linear, the risk-weighted expected utility is equal to its expected utility. But Buchak proposes that to be risk averse with respect to utility risks is to have a *convex risk function*.

We assume the dm's utility of money is linear, her risk function is r(p) = p^2, and the two states of the table are equally probable. The risk-weighted expected utility of the first gamble is thus 0 + 0.25 * (100 - 0) = 25 units of utility. That of the second gamble: 40 + 0.25 (40-40) = 40 units of utility. On this view, it's rational to prefer $40 for sure.

The convexity of the risk function guarantees that gains above the minimum utility value will always count for less according to the risk-weighted expected utility principle, compared to the traditional expected utility principle. And if we make the better outcome more probable, this increase will matter more the more likely the better outcome is to obtain.

Buchak and Arrow don't disagree about whether it's rationally permissible to have a concave utility function, but whether the concavity of the utility function is *sufficient* for making sense of reasonable intuitions about risk aversion.  

A possible drawback for the risk-weighted expected utility principle is that it makes the dm vulnerable to pragmatic arguments of the type discussed in chapter 8.

## 10.3. Epistemic risk aversion

The upshot of Ellsberg's paradox in chapter 4 is that it's rationally permissible to prefer a lottery with known probabilities than a similar lottery with unknown probabilities, even if the expected utility of the two lotteries is the same.

Gärdenfors and Sahlin present a simple type of example to illustrate the epistemic dimensions of risk aversion.

There are 3 tennis matches. In game A, you know all about the players and you can say that there's a 50% chance for each player to win. There's no additional piece of info that you're not aware of that could make you drastically revise this probability function.

In game B you know nothing about the players. You conclude 50-50 chances of winning for each player, but this isn't epistemically robust. If you were to learn a bit more about their sills and past performance, you'd change your probability assignment.

In game C, you've heard that one player is much better than the other. But you don't know who it is. So you give both 50-50 chance of winning, but you know this isn't epistemically robust.

You're offered to bet on each match, in each you win $100 or lose $100. Gärdenfors and Sahlin note that a strict Bayesian would say that the dm should be willing to bet at equal odds on one of the players winning on one of the matches iff she's willing to place a similar bet in the two other matches. But it's seems perfectly rational to bet on A but not on B and C, because the bet on A is more *reliable* than the bet on the others.

They propose that the dm should model her unreliable probabilities with several parallel probability functions. They propose the *maximin criterion for expected utilities (MMEU)*. This rule is risk averse in the sense that it tells you to expect the worst. If the quantity of information at hand is low, be cautious.